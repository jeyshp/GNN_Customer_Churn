{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in dataset\n",
    "full_dataset = pd.read_csv(\"Telco.csv\")\n",
    "dataset = pd.read_csv(\"Telco.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tenure            0\n",
      "MonthlyCharges    0\n",
      "TotalCharges      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing data \n",
    "\n",
    "def replace_values(df):\n",
    "    df = df.map(lambda x: x.replace(\"No internet service\", \"No\") if isinstance(x, str) else x)\n",
    "    df = df.map(lambda x: x.replace(\"No phone service\", \"No\") if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "dataset = replace_values(dataset)\n",
    "categorical_feats = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', \n",
    "                       'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n",
    "                       'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', \n",
    "                       'PaperlessBilling', 'PaymentMethod']  # apply one-hot encoding\n",
    "dataset = dataset.drop(\"customerID\", axis = 1)\n",
    "le = LabelEncoder()\n",
    "for col in categorical_feats:\n",
    "    dataset[col] = le.fit_transform(dataset[col])\n",
    "labels = dataset['Churn'].values  # Target variable\n",
    "dataset = dataset.drop(\"Churn\", axis = 1)\n",
    "dataset[['tenure', 'MonthlyCharges', 'TotalCharges']] = dataset[['tenure', 'MonthlyCharges', 'TotalCharges']].replace(r'^\\s*$', np.nan, regex=True)\n",
    "dataset[['tenure', 'MonthlyCharges', 'TotalCharges']] = dataset[['tenure', 'MonthlyCharges', 'TotalCharges']].apply(pd.to_numeric, errors='coerce')\n",
    "dataset[['tenure', 'MonthlyCharges', 'TotalCharges']] = dataset[['tenure', 'MonthlyCharges', 'TotalCharges']].fillna(dataset[['tenure', 'MonthlyCharges', 'TotalCharges']].mean())\n",
    "\n",
    "print(dataset[['tenure', 'MonthlyCharges', 'TotalCharges']].isna().sum())\n",
    "scaler = StandardScaler()\n",
    "dataset[['tenure', 'MonthlyCharges', 'TotalCharges']] = scaler.fit_transform(dataset[['tenure', 'MonthlyCharges', 'TotalCharges']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender                int64\n",
      "SeniorCitizen         int64\n",
      "Partner               int64\n",
      "Dependents            int64\n",
      "tenure              float64\n",
      "PhoneService          int64\n",
      "MultipleLines         int64\n",
      "InternetService       int64\n",
      "OnlineSecurity        int64\n",
      "OnlineBackup          int64\n",
      "DeviceProtection      int64\n",
      "TechSupport           int64\n",
      "StreamingTV           int64\n",
      "StreamingMovies       int64\n",
      "Contract              int64\n",
      "PaperlessBilling      int64\n",
      "PaymentMethod         int64\n",
      "MonthlyCharges      float64\n",
      "TotalCharges        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "dataset.head(5)\n",
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KNN-based graph (10 nearest neighbors)\n",
    "knn = NearestNeighbors(n_neighbors=10)\n",
    "knn.fit(dataset)\n",
    "edges = knn.kneighbors_graph(dataset, n_neighbors=10, mode='connectivity')\n",
    "edge_index = torch.tensor(edges.nonzero(), dtype=torch.long)  \n",
    "\n",
    "labels = full_dataset['Churn'].map({'Yes': 1, 'No': 0}).values  \n",
    "\n",
    "# Convert features and labels to tensors\n",
    "x = torch.tensor(dataset.values, dtype=torch.float)\n",
    "y = torch.tensor(labels, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)  # Softmax for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Fold 1: Accuracy = 0.8091, F1-Score = 0.6096\n",
      "\n",
      "Fold 2\n",
      "Fold 2: Accuracy = 0.7970, F1-Score = 0.5879\n",
      "\n",
      "Fold 3\n",
      "Fold 3: Accuracy = 0.8190, F1-Score = 0.6244\n",
      "\n",
      "Fold 4\n",
      "Fold 4: Accuracy = 0.7891, F1-Score = 0.5438\n",
      "\n",
      "Fold 5\n",
      "Fold 5: Accuracy = 0.7884, F1-Score = 0.5512\n",
      "\n",
      "Final Cross-Validation Results:\n",
      "Mean Accuracy: 0.8005 ± 0.0119\n",
      "Mean F1-Score: 0.5834 ± 0.0316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Define cross-validation strategy (Stratified K-Fold)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store accuracy and F1-score for each fold\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(dataset, labels)):\n",
    "    print(f\"\\nFold {fold + 1}\")\n",
    "\n",
    "    # Create PyTorch Geometric Data object for this fold\n",
    "    train_mask = torch.zeros(y.shape, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(y.shape, dtype=torch.bool)\n",
    "    train_mask[train_idx] = True\n",
    "    test_mask[test_idx] = True\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "    # Initialize GNN model\n",
    "    model = GNN(in_channels=x.shape[1], hidden_channels=16, out_channels=2)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train GNN\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)  # Forward pass\n",
    "        loss = loss_fn(out[train_mask], data.y[train_mask])  # Compute loss only on training set\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate Model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        pred = out.argmax(dim=1)\n",
    "\n",
    "    # Compute metrics for this fold\n",
    "    accuracy = accuracy_score(data.y[test_mask].numpy(), pred[test_mask].numpy())\n",
    "    f1 = f1_score(data.y[test_mask].numpy(), pred[test_mask].numpy())\n",
    "\n",
    "    print(f\"Fold {fold + 1}: Accuracy = {accuracy:.4f}, F1-Score = {f1:.4f}\")\n",
    "    accuracies.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print Final Cross-Validation Scores\n",
    "print(\"\\nFinal Cross-Validation Results:\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
    "print(f\"Mean F1-Score: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8047706943064035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Predicted labels\n",
    "out = model(data.x, data.edge_index)\n",
    "pred = out.argmax(dim=1)\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(data.y.numpy(), pred.numpy())\n",
    "f1 = f1_score(data.y.numpy(), pred.numpy())\n",
    "\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc330",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
